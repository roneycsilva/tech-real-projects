# ğŸ¦ Bank Resilience 2026: Ecossistema de Processamento BancÃ¡rio Multi-Cloud

---

## 1ï¸âƒ£ IntroduÃ§Ã£o

O **Bank Resilience 2026** Ã© um projeto de estudo avanÃ§ado que simula a arquitetura de um sistema bancÃ¡rio resiliente, projetado para suportar **altos volumes de transaÃ§Ãµes financeiras distribuÃ­das entre mÃºltiplos provedores de nuvem (AWS e Azure)** sem risco de perda de dados.

A proposta reproduz desafios reais do setor financeiro, onde **disponibilidade contÃ­nua, integridade transacional, rastreabilidade e governanÃ§a de dados** sÃ£o requisitos obrigatÃ³rios. A arquitetura foi concebida com base em boas prÃ¡ticas observadas no ecossistema de adquirÃªncia, processamento de pagamentos e sistemas bancÃ¡rios, aproximando o projeto de cenÃ¡rios corporativos encontrados em instituiÃ§Ãµes financeiras e empresas de meios de pagamento.

Este projeto nÃ£o foca apenas na construÃ§Ã£o de uma API, mas na simulaÃ§Ã£o de um **ecossistema de processamento transacional**, onde diferentes componentes desempenham papÃ©is bem definidos dentro de um fluxo crÃ­tico de dados financeiros.

---

### ğŸ¯ Objetivos TÃ©cnicos do Projeto

- Garantir que **nenhuma transaÃ§Ã£o financeira seja perdida**, mesmo diante de falhas temporÃ¡rias de rede ou indisponibilidade de serviÃ§os.  
- Implementar **desacoplamento entre recepÃ§Ã£o e processamento**, utilizando mensageria assÃ­ncrona.
- Construir um pipeline de dados **escalÃ¡vel, auditÃ¡vel e tolerante a falhas**.
- Aplicar conceitos de **consistÃªncia eventual**, comuns em arquiteturas distribuÃ­das.
- Simular um processo de **conciliaÃ§Ã£o financeira**, prÃ¡tica essencial em ambientes bancÃ¡rios e de adquirÃªncia.

---

### ğŸ§© Problema Arquitetural Abordado

Em sistemas financeiros, o processamento sÃ­ncrono representa um alto risco: qualquer falha pode gerar perda de dados ou inconsistÃªncias contÃ¡beis. Para mitigar esse risco, a arquitetura deste projeto utiliza um **modelo orientado a eventos (Event-Driven)**, utilizando o **Apache Kafka (Aiven)** como um log imutÃ¡vel de transaÃ§Ãµes.

O fluxo principal segue o padrÃ£o:
`Recebimento (API) â†’ Log de Eventos (Kafka) â†’ Processamento AssÃ­ncrono (Worker) â†’ PersistÃªncia (MongoDB) â†’ Auditoria`

Esse modelo garante:

* **ResiliÃªncia de Log:** Diferente de filas comuns, o Kafka armazena o histÃ³rico. Se o Worker falhar ao processar os R$ 91 milhÃµes, a mensagem permanece no **Offset** para reprocessamento.
* **Isolamento e Desacoplamento:** A API no Railway nÃ£o precisa saber se o Worker local estÃ¡ ativo; o Kafka gerencia a retenÃ§Ã£o dos dados.
* **Garantia de Entrega (At-Least-Once):** Elimina o risco de "transaÃ§Ãµes perdidas" no caminho entre a nuvem e o processador local.
* **ConsistÃªncia Eventual:** Garante que, mesmo sob carga, todos os dados serÃ£o eventualmente liquidados no MongoDB.

---

### ğŸ›ï¸ VisÃ£o de Arquitetura BancÃ¡ria Aplicada

A estrutura do projeto foi consolidada com base em padrÃµes de **MissÃ£o CrÃ­tica** e alta disponibilidade:

* **Persistence by Default:** Uso do **Apache Kafka na Aiven** como buffer transacional de alto throughput e baixa latÃªncia.
* **Observabilidade Nativa:** Monitoramento de saÃºde do cluster via logs e mÃ©tricas em tempo real (Aiven Metrics).
* **SeguranÃ§a de Dados BancÃ¡rios:** ImplementaÃ§Ã£o de conexÃ£o criptografada via **SSL/TLS**, utilizando certificados (CA, Access Key e Certificate) para autenticaÃ§Ã£o entre os sistemas.
* **EstratÃ©gia HÃ­brida e Multi-Cloud:** IntegraÃ§Ã£o real entre **Railway (API)**, **Aiven (Kafka Cloud)** e processamento local, simulando um ambiente bancÃ¡rio distribuÃ­do.

Essa abordagem foca em pilares inegociÃ¡veis do setor financeiro:

- [x] **Integridade:** Garantia de que o valor transacionado Ã© exatamente o valor persistido.
- [x] **Auditabilidade:** Uso do **Kafka REST API** para visualizaÃ§Ã£o e auditoria das mensagens diretamente no broker.
- [x] **RecuperaÃ§Ã£o de Desastres:** Capacidade de reconstruir o estado do banco de dados a partir do log de mensagens do Kafka.

---

### ğŸ“š Contexto Educacional e Profissional

Embora seja um projeto educacional, sua modelagem foi guiada por uma **visÃ£o profissional de arquitetura bancÃ¡ria**, conectando prÃ¡ticas de engenharia de software, mensageria, tratamento de dados e governanÃ§a ao contexto de sistemas financeiros distribuÃ­dos.

O projeto serve como um estudo aplicado de:

* **Arquiteturas Resilientes:** ImplementaÃ§Ã£o de clusters gerenciados (Aiven e CloudAMQP) com alta disponibilidade.
* **Processamento AssÃ­ncrono:** Uso de mensageria para evitar o bloqueio de threads e perda de requisiÃ§Ãµes.
* **ETL Financeiro:** Fluxo de ExtraÃ§Ã£o (API), TransformaÃ§Ã£o (Worker) e Carga (MongoDB).
* **ConciliaÃ§Ã£o de Dados:** Garantia de que o que foi registrado no Kafka (Log de Eventos) foi devidamente liquidado no Banco de Dados.
* **Boas PrÃ¡ticas de AdquirÃªncia:** SimulaÃ§Ã£o de fluxos de liquidaÃ§Ã£o financeira seguindo padrÃµes de seguranÃ§a e auditabilidade.

---

### ğŸ¯ Objetivos do Projeto

Este projeto foi concebido com foco em boas prÃ¡ticas de engenharia aplicadas a sistemas financeiros distribuÃ­dos. Os objetivos abrangem conceitos de arquitetura resiliente, governanÃ§a de dados e processamento transacional de missÃ£o crÃ­tica.

* **Zero Data Loss:** Garantir que **nenhuma transaÃ§Ã£o financeira seja perdida**, mesmo sob falhas temporÃ¡rias de rede, indisponibilidade de serviÃ§os ou picos de carga, utilizando o **Apache Kafka** como log persistente.
* **Desacoplamento de Camadas:** Implementar a separaÃ§Ã£o total entre recepÃ§Ã£o e processamento, utilizando mensageria assÃ­ncrona como mecanismo de defesa da infraestrutura.
* **Escalabilidade e Observabilidade:** Construir um pipeline de dados observÃ¡vel via mÃ©tricas de infraestrutura e logs, preparado para cenÃ¡rios de alto volume transacional.
* **ConsistÃªncia Eventual:** Aplicar princÃ­pios de consistÃªncia comum em sistemas bancÃ¡rios distribuÃ­dos, onde o estado final do saldo Ã© garantido apÃ³s o processamento da fila.
* **ConciliaÃ§Ã£o e Integridade:** Simular um processo de conciliaÃ§Ã£o financeira, validando se o valor emitido (Ex: R$ 91 MilhÃµes) Ã© exatamente o valor persistido.
* **Rastreabilidade Ponta a Ponta:** Garantir que cada transaÃ§Ã£o possa ser rastreada desde o Producer atÃ© a liquidaÃ§Ã£o no **MongoDB**, permitindo auditoria total.
* **PadrÃµes de AdquirÃªncia:** Modelar o sistema com base em fluxos reais de processamento de pagamentos, aproximando o estudo dos maiores players do mercado financeiro.
---

### ğŸ§© Problema Arquitetural Abordado

Em sistemas financeiros, o processamento sÃ­ncrono representa um alto risco: qualquer falha pode gerar perda de dados ou inconsistÃªncias contÃ¡beis. Para mitigar esse risco, a arquitetura deste projeto utiliza um **modelo orientado a mensageria**, onde o broker (**Apache Kafka na Aiven**) atua como camada de seguranÃ§a entre a entrada e o processamento dos dados.

O fluxo principal segue o padrÃ£o:
`Recebimento (API) â†’ Fila de Mensagens (Kafka/RabbitMQ) â†’ Processamento AssÃ­ncrono (Worker) â†’ PersistÃªncia (MongoDB) â†’ Auditoria`

Essa abordagem Ã© amplamente utilizada em plataformas de pagamento e sistemas bancÃ¡rios modernos, pois permite:

* **ResiliÃªncia a falhas temporÃ¡rias:** O Kafka retÃ©m as mensagens mesmo que o processador esteja offline.
* **Mecanismo de retry automÃ¡tico:** Facilita o reprocessamento em caso de erros de negÃ³cio.
* **Isolamento de responsabilidades:** A API foca na recepÃ§Ã£o de alta performance, enquanto o Worker foca na regra de negÃ³cio.
* **ProteÃ§Ã£o contra sobrecarga:** O banco de dados (MongoDB) nÃ£o recebe picos diretos, mas sim um fluxo controlado pelo Worker.
* **ConsistÃªncia eventual:** CaracterÃ­stica fundamental em arquiteturas distribuÃ­das de larga escala.

Dessa forma, a fila atua como uma **camada de seguranÃ§a lÃ³gica**, garantindo que cada transaÃ§Ã£o (como o caso real de R$ 91 milhÃµes simulado) seja processada de forma confiÃ¡vel, rastreÃ¡vel e auditÃ¡vel, mesmo em cenÃ¡rios adversos de infraestrutura.

## 2ï¸âƒ£ IntegraÃ§Ã£o entre Ferramentas

A arquitetura do **Bank Resilience 2026** Ã© composta por um conjunto de tecnologias que, integradas, formam um ecossistema de processamento transacional resiliente. Cada ferramenta desempenha um papel especÃ­fico dentro do fluxo de dados, refletindo a separaÃ§Ã£o de responsabilidades comum em sistemas financeiros de alta disponibilidade.

Essa composiÃ§Ã£o tecnolÃ³gica foi definida com base em boas prÃ¡ticas de mercado, priorizando **desacoplamento, escalabilidade, observabilidade e confiabilidade operacional**. O objetivo Ã© garantir que a recepÃ§Ã£o, o transporte, o processamento e a persistÃªncia das transaÃ§Ãµes ocorram de maneira segura e auditÃ¡vel.

### ğŸ› ï¸ Matriz de Responsabilidades TÃ©cnicas

| Tecnologia | Papel no Sistema |
| :--- | :--- |
| **Node.js** | Ambiente de execuÃ§Ã£o da API e dos serviÃ§os de processamento (Workers) |
| **Apache Kafka (Aiven)** | **Broker de Eventos (Principal)**: Log imutÃ¡vel para auditoria e persistÃªncia de alta performance |
| **RabbitMQ (CloudAMQP)** | **Broker de Mensageria (Suporte)**: Gerenciamento de filas e resiliÃªncia transacional |
| **MongoDB** | PersistÃªncia das transaÃ§Ãµes financeiras liquidadas em modelo NoSQL |
| **SSL/TLS Certificates** | SeguranÃ§a na comunicaÃ§Ã£o entre o Worker local e o cluster na Nuvem (Aiven) |
| **Railway** | Plataforma de infraestrutura para deploy contÃ­nuo (CI/CD) da API bancÃ¡ria |
| **Express** | Camada HTTP responsÃ¡vel por expor os endpoints da API |
| **Postman** | Ferramenta de testes de carga e validaÃ§Ã£o de cenÃ¡rios de sucesso e falha |

Essa integraÃ§Ã£o forma um pipeline de dados distribuÃ­do, onde cada componente atua de forma coordenada para garantir que as transaÃ§Ãµes sejam processadas com integridade, rastreabilidade e total tolerÃ¢ncia a falhas.

## 3ï¸âƒ£ Arquitetura do Sistema

A arquitetura do sistema foi desenhada com foco em **resiliÃªncia, desacoplamento e confiabilidade transacional**, princÃ­pios fundamentais em ambientes financeiros. Em vez de concentrar todas as responsabilidades em um Ãºnico serviÃ§o, o fluxo foi dividido em camadas especializadas, permitindo maior controle sobre falhas, escalabilidade e auditoria.

O modelo adotado segue uma abordagem **Event-Driven (Orientada a Eventos)**, onde a mensageria atua como elo entre a entrada e o processamento. Essa estratÃ©gia reduz o impacto de indisponibilidades, evita sobrecarga de componentes crÃ­ticos e possibilita rastrear o ciclo de vida de cada transaÃ§Ã£o de alto valor.

### ğŸ”„ Fluxo de Dados e IntegraÃ§Ã£o HÃ­brida

Abaixo estÃ¡ a visÃ£o do pipeline de dados, destacando a coexistÃªncia dos brokers para mÃ¡xima disponibilidade:

```text
          ğŸŒ Cliente / SimulaÃ§Ã£o ETL
                 â”‚
                 â–¼
        ğŸš€ API BancÃ¡ria (Railway)
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼
  ğŸ“¨ RabbitMQ       ğŸ¡ Apache Kafka
  (CloudAMQP)         (Aiven Cloud)
        â”‚                 â”‚
        â”‚         ğŸ” ConexÃ£o SSL/TLS
        â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
        âš™ï¸ Worker de Processamento
        (Consumo e ValidaÃ§Ã£o)
                 â”‚
                 â–¼
        ğŸ—„ï¸ MongoDB (PersistÃªncia)
                 â”‚
                 â–¼
        ğŸ“Š Auditoria & ReconciliaÃ§Ã£o
```
A arquitetura do projeto foi estruturada para separar claramente as responsabilidades de **IngestÃ£o**, **Processamento** e **Auditoria**, prÃ¡tica comum em sistemas financeiros distribuÃ­dos. Essa divisÃ£o favorece a escalabilidade, facilita a manutenÃ§Ã£o e reduz o acoplamento entre os componentes, permitindo que cada camada evolua de forma independente.

O modelo tambÃ©m reforÃ§a princÃ­pios de governanÃ§a de dados e rastreabilidade, essenciais em ambientes bancÃ¡rios e de adquirÃªncia, onde Ã© necessÃ¡rio compreender todo o ciclo de vida de uma transaÃ§Ã£o â€” da entrada atÃ© a consolidaÃ§Ã£o final.

A organizaÃ§Ã£o do repositÃ³rio reflete essa arquitetura em camadas:


## 4ï¸âƒ£ Estrutura do Projeto
A organizaÃ§Ã£o do repositÃ³rio segue o princÃ­pio de **separaÃ§Ã£o de responsabilidades**, dividindo a soluÃ§Ã£o entre camadas de ingestÃ£o, processamento, dados e documentaÃ§Ã£o. Essa estrutura facilita a escalabilidade, manutenÃ§Ã£o e entendimento da arquitetura do sistema.

```text
ğŸ“¦ bank-resilience-2026
â”£ ğŸ“‚ api-railway
â”ƒ â”£ ğŸ“„ index.js                # API Express que recebe as transaÃ§Ãµes
â”ƒ â”£ ğŸ“„ ingestao.js              # ETL CSV â†’ RabbitMQ
â”ƒ â”£ ğŸ“„ producer-kafka.js        # Publicador de transaÃ§Ãµes para o Kafka (Aiven)
â”ƒ â”— ğŸ“„ .env                     # ConfiguraÃ§Ãµes Railway / CloudAMQP / Aiven
â”ƒ
â”£ ğŸ“‚ data
â”ƒ â”— ğŸ“„ transacoes_brutas.csv    # Base de dados bruta para simulaÃ§Ã£o
â”ƒ
â”£ ğŸ“‚ local-worker
â”ƒ â”£ ğŸ“„ worker.js                # Consumidor RabbitMQ â†’ MongoDB
â”ƒ â”£ ğŸ“„ worker-kafka.js          # Consumidor Kafka (SSL) â†’ MongoDB
â”ƒ â”£ ğŸ“„ auditoria.js             # ConciliaÃ§Ã£o e validaÃ§Ã£o financeira
â”ƒ â”£ ğŸ“„ relatorio_final.js       # ExportaÃ§Ã£o de transaÃ§Ãµes liquidadas
â”ƒ â”— ğŸ“„ .env                     # String de conexÃ£o Mongo e Aiven Cloud
â”ƒ
â”£ ğŸ“‚ certs                      # ğŸ” Certificados SSL/TLS (CA, Access Key, Cert)
â”ƒ â”— ğŸ“„ (Arquivos .pem para conexÃ£o segura com Kafka Aiven)
â”ƒ
â”£ ğŸ“‚ img
â”ƒ â”— ğŸ–¼ï¸ (Prints de dashboards Kafka, RabbitMQ e MongoDB)
â”ƒ
â”£ ğŸ“‚ infra
â”ƒ â”— âš™ï¸ (ConfiguraÃ§Ãµes de brokers e scripts de apoio)
â”ƒ
â”— ğŸ“„ README.md                  # DocumentaÃ§Ã£o tÃ©cnica detalhada

```
## 5ï¸âƒ£ Camada de Dados & ETL (Extract, Transform, Load)

O sistema foi projetado para processar **transaÃ§Ãµes financeiras com caracterÃ­sticas tÃ­picas de ambientes bancÃ¡rios**, onde a qualidade e a padronizaÃ§Ã£o dos dados sÃ£o fatores crÃ­ticos para garantir integridade contÃ¡bil e confiabilidade dos relatÃ³rios.

Antes de serem enviadas para a nuvem e inseridas no fluxo de mensageria, as transaÃ§Ãµes passam por um processo estruturado de **ETL**. Essa etapa Ã© fundamental para evitar inconsistÃªncias, erros de tipo e falhas de processamento em etapas posteriores do pipeline.

### ğŸ”„ O Ciclo de Vida do Dado Transacional:

1.  **Extract (ExtraÃ§Ã£o):** Leitura da base bruta (CSV) simulando a recepÃ§Ã£o de arquivos de remessa bancÃ¡ria ou logs de transaÃ§Ãµes de adquirÃªncia.
2.  **Transform (TransformaÃ§Ã£o):** NormalizaÃ§Ã£o de campos crÃ­ticos (valores, datas, IDs de transaÃ§Ã£o) e aplicaÃ§Ã£o de regras de negÃ³cio para garantir o layout esperado pelo **Apache Kafka**.
3.  **Load (Carga):** Disparo das transaÃ§Ãµes tratadas para o broker na nuvem (**Aiven**), utilizando criptografia **SSL/TLS** para garantir que o dado financeiro trafegue de forma segura.

O tratamento aplicado simula prÃ¡ticas reais onde dados de diferentes origens precisam ser normalizados antes de entrar nos sistemas centrais. Com o uso do Kafka, ganhamos a capacidade de **Auditoria em Tempo Real**, onde cada etapa do ETL pode ser verificada diretamente no log de mensagens do broker.

### ğŸ”„ Etapas do ETL

| Etapa | DescriÃ§Ã£o |
|------|-----------|
| **Limpeza** | Regex para remover `R$`, espaÃ§os e caracteres invÃ¡lidos |
| **ConversÃ£o** | TransformaÃ§Ã£o de `string` â†’ nÃºmero decimal |
| **PadronizaÃ§Ã£o** | ConversÃ£o de datas para o padrÃ£o ISO 8601 |
| **Enriquecimento** | InclusÃ£o de metadados como origem da nuvem (AWS/Azure) |
| **ValidaÃ§Ã£o** | Estrutura JSON validada antes do envio para a fila |

Esse processo garante que os dados cheguem ao sistema de mensageria jÃ¡ estruturados, reduzindo falhas no processamento assÃ­ncrono e aumentando a confiabilidade do ciclo transacional.

## 6ï¸âƒ£ Scripts e Responsabilidades

A camada de scripts representa a implementaÃ§Ã£o prÃ¡tica da arquitetura proposta. Cada arquivo possui uma responsabilidade bem definida dentro do fluxo transacional, reforÃ§ando o princÃ­pio de **separaÃ§Ã£o de responsabilidades** (Single Responsibility Principle), fundamental em sistemas financeiros de alta disponibilidade.

### ğŸ› ï¸ DivisÃ£o Funcional dos Componentes

#### ğŸ“¤ Camada de IngestÃ£o e ProduÃ§Ã£o (API/Cloud)
* **`index.js` (API Railway):** Porta de entrada para requisiÃ§Ãµes externas, simulando o recebimento de transaÃ§Ãµes em tempo real.
* **`ingestao.js`:** Script responsÃ¡vel pelo processo de ETL em massa (CSV para Broker), garantindo a carga inicial do sistema.
* **`producer-kafka.js`:** ImplementaÃ§Ã£o especializada para envio de dados ao **Apache Kafka**, utilizando autenticaÃ§Ã£o segura via certificados SSL/TLS.

#### âš™ï¸ Camada de Processamento (Local Workers)
* **`worker.js`:** Consumidor dedicado ao RabbitMQ; foca em resiliÃªncia e retentativas de processamento.
* **`worker-kafka.js`:** Consumidor de alta performance para o Kafka na **Aiven**. Realiza o "de-serialize" das mensagens criptografadas e a persistÃªncia final no MongoDB.
* **`auditoria.js`:** Script de inteligÃªncia que realiza a conciliaÃ§Ã£o financeira, verificando se todos os eventos emitidos foram devidamente liquidados.

### ğŸ›¡ï¸ BenefÃ­cios desta OrganizaÃ§Ã£o:
* **Baixo Acoplamento:** A falha de um script (ex: Worker RabbitMQ) nÃ£o impede o funcionamento do outro (ex: Worker Kafka).
* **Escalabilidade Independente:** Permite evoluir a lÃ³gica de persistÃªncia sem alterar a lÃ³gica de recepÃ§Ã£o da API.
* **Observabilidade Granular:** Facilita a identificaÃ§Ã£o de gargalos em etapas especÃ­ficas do pipeline de dados.

---

### ğŸ› ï¸ IngestÃ£o de Dados (`ingestao.js` / `ingestao-kafka.js`)

Esta camada Ã© responsÃ¡vel pela entrada estruturada e higienizaÃ§Ã£o das transaÃ§Ãµes no ecossistema de mensageria, atuando como o primeiro filtro de qualidade do pipeline.

**FunÃ§Ãµes principais:**

* **Processamento de Dataset:** Leitura e parsing de um conjunto de **627 registros** reais de transaÃ§Ãµes.
* **NormalizaÃ§Ã£o de Dados:** ConversÃ£o de formatos brutos (CSV) para objetos JSON tipados, prontos para o consumo por sistemas distribuÃ­dos.
* **Dual-Broker Support:** Capacidade de despachar transaÃ§Ãµes tanto para o **RabbitMQ (CloudAMQP)** quanto para o **Apache Kafka (Aiven)**.
* **SeguranÃ§a e Criptografia:** No fluxo do Kafka, o script gerencia a conexÃ£o segura via protocolos SSL, garantindo que o dado financeiro saia da origem protegido.
* **Backpressure e Rate Control:** Controle de cadenciamento para evitar sobrecarga na API de destino e garantir a estabilidade do cluster na nuvem.

Essa etapa simula com precisÃ£o a entrada de dados provenientes de mÃºltiplas origens (Multi-Cloud), onde a **ingestÃ£o** precisa ser resiliente o suficiente para lidar com grandes volumes sem perda de pacotes.

---

### ğŸ‘· Processamento AssÃ­ncrono (`worker.js` / `worker-kafka.js`)

Componente central da resiliÃªncia do sistema, responsÃ¡vel pelo consumo inteligente das mensagens e pela persistÃªncia garantida das transaÃ§Ãµes.

**LÃ³gica de Processamento e Confiabilidade:**

* **Controle de VazÃ£o (Backpressure):** * No **RabbitMQ**, utiliza `prefetch(1)` para processar uma transaÃ§Ã£o por vez, evitando gargalos de memÃ³ria.
    * No **Kafka**, utiliza a estratÃ©gia de **Manual Commit**, onde o offset sÃ³ Ã© atualizado apÃ³s a confirmaÃ§Ã£o de sucesso.
* **Garantia de PersistÃªncia:** O `ack` (RabbitMQ) ou o `commit` (Kafka) sÃ³ Ã© executado apÃ³s a confirmaÃ§Ã£o de gravaÃ§Ã£o no **MongoDB**, eliminando o risco de mensagens perdidas entre o broker e o banco.
* **SeguranÃ§a de ConexÃ£o:** O worker do Kafka opera sob **SSL/TLS**, realizando o handshake seguro com o cluster na nuvem atravÃ©s dos certificados de acesso.
* **IdempotÃªncia:** Preparado para evitar a duplicidade de registros (como os R$ 91 milhÃµes simulados), garantindo que cada transaÃ§Ã£o seja Ãºnica no banco de dados.

Este modelo reproduz com fidelidade o processamento de **MissÃ£o CrÃ­tica**, onde a consistÃªncia do dado financeiro Ã© prioritÃ¡ria em relaÃ§Ã£o Ã  velocidade bruta.

---

### ğŸ“Š Auditoria Financeira e ConciliaÃ§Ã£o (`auditoria.js`)

O componente de auditoria representa a camada de governanÃ§a do **Bank Resilience 2026**. Ele foi desenvolvido para garantir a integridade contÃ¡bil do sistema, realizando a reconciliaÃ§Ã£o entre as mensagens trafegadas no broker (**Apache Kafka na Aiven**) e os registros liquidados na camada de persistÃªncia (**MongoDB**).

Este script nÃ£o realiza apenas uma contagem simples, mas sim uma validaÃ§Ã£o de estado entre sistemas distribuÃ­dos.

**FunÃ§Ãµes e Rigor TÃ©cnico:**

* **AgregaÃ§Ã£o de Dados em Larga Escala:** Utiliza o *Aggregation Framework* do MongoDB para processar e somar valores monetÃ¡rios de alta precisÃ£o, garantindo que nÃ£o haja perda de decimais durante o fluxo assÃ­ncrono.
* **ConciliaÃ§Ã£o de Log de Eventos:** Confronta o volume de mensagens produzidas no tÃ³pico do Kafka com os documentos persistidos. Como o Kafka na Aiven atua como um log imutÃ¡vel, ele serve como a "fonte da verdade" para auditar se o Worker processou todos os eventos.
* **ValidaÃ§Ã£o de Integridade Financeira:** Verifica se o montante total transacionado condiz com o dataset de entrada, assegurando que a infraestrutura (SSL/TLS, Brokers e Workers) nÃ£o introduziu inconsistÃªncias nos dados.

**Resultado Consolidado da OperaÃ§Ã£o:**

Abaixo, os dados extraÃ­dos apÃ³s o processamento do pipeline hÃ­brido, provando a eficÃ¡cia da arquitetura:

| Indicador de Auditoria | Valor Auditado | Status da TransaÃ§Ã£o |
| :--- | :--- | :--- |
| **Volume Financeiro Total** | **R$ 91.484.956,73** | âœ… 100% Conciliado |
| **Integridade de Dados** | **0% de perda** | âœ… Verificado |
| **Total de Registros** | **627 transaÃ§Ãµes** | âœ… Auditado |

> [!IMPORTANT]
> Este processo simula o **Settlement (LiquidaÃ§Ã£o)** bancÃ¡rio. Em um cenÃ¡rio real de adquirÃªncia, essa auditoria Ã© o que garante que o lojista receba exatamente o valor capturado, livre de falhas de infraestrutura ou erros de comunicaÃ§Ã£o entre nuvens.

---

### ğŸ“ GeraÃ§Ã£o de RelatÃ³rios e ExportaÃ§Ã£o (`relatorio_final.js`)

O script de geraÃ§Ã£o de relatÃ³rios constitui a camada de saÃ­da e inteligÃªncia de dados do sistema. Ele Ã© responsÃ¡vel por extrair o estado final das transaÃ§Ãµes que foram processadas de forma assÃ­ncrona pelo **Apache Kafka (Aiven)** e liquidadas no **MongoDB**, transformando logs tÃ©cnicos em ativos de auditoria e BI.

Diferente de uma simples exportaÃ§Ã£o, este componente consolida a prova de que o fluxo transacional de **R$ 91.484.956,73** foi concluÃ­do com sucesso.

**FunÃ§Ãµes e Detalhamento TÃ©cnico:**

* **ExtraÃ§Ã£o de Snapshot Transacional:** O script realiza uma varredura na camada de persistÃªncia para consolidar transaÃ§Ãµes que transitaram pelo ecossistema de mensageria, garantindo que apenas dados confirmados (*committed*) via Worker sejam exportados.
* **NormalizaÃ§Ã£o para BI e Contabilidade:** Converte a estrutura de documentos NoSQL e as mensagens serializadas no Kafka em um formato CSV estruturado (UTF-8), permitindo a ingestÃ£o imediata por ferramentas de anÃ¡lise financeira e auditoria externa.
* **Suporte Ã  ReconciliaÃ§Ã£o HÃ­brida:** Atua como o ponto de conferÃªncia final para validar se o volume de transaÃ§Ãµes recebido pela API no Railway corresponde exatamente ao volume exportado, fechando o ciclo de governanÃ§a iniciado no broker.
* **Auditabilidade de Dados BancÃ¡rios:** O relatÃ³rio gerado serve como evidÃªncia de conformidade, permitindo rastrear cada linha financeira de volta ao seu evento de origem no cluster da Aiven, garantindo transparÃªncia total em cenÃ¡rios de fiscalizaÃ§Ã£o.

**ParÃ¢metros de OperaÃ§Ã£o:**

| Atributo TÃ©cnico | EspecificaÃ§Ã£o | Objetivo |
| :--- | :--- | :--- |
| **Formato de Arquivo** | CSV Padronizado | Interoperabilidade entre sistemas bancÃ¡rios |
| **Origem do Dado** | MongoDB (PÃ³s-Kafka) | Garantir que apenas dados liquidados sejam reportados |
| **MÃ©trica de Sucesso** | Integridade dos R$ 91M | Prova de que a mensageria nÃ£o gerou perdas |
| **SeguranÃ§a** | SanitizaÃ§Ã£o de dados | ProteÃ§Ã£o de informaÃ§Ãµes sensÃ­veis na exportaÃ§Ã£o |

> [!TIP]
> Em ambientes de **AdquirÃªncia**, este relatÃ³rio Ã© o que define o "Settlement" (LiquidaÃ§Ã£o). Se o relatÃ³rio final gerado pelo script for idÃªntico ao dataset de ingestÃ£o, a arquitetura provou sua **ResiliÃªncia BancÃ¡ria** contra falhas de rede ou picos de carga.

---

### ğŸ“¥ Bases de Dados e Ciclo de Vida da InformaÃ§Ã£o

Esta seÃ§Ã£o detalha os artefatos de dados que sustentam o fluxo transacional do projeto. O ciclo de vida da informaÃ§Ã£o foi projetado para garantir a **linhagem dos dados** (*data lineage*), desde o estado bruto atÃ© a liquidaÃ§Ã£o final, passando pela camada de mensageria segura no **Apache Kafka**.

A integridade deste fluxo Ã© o que permitiu o processamento bem-sucedido de **R$ 91.484.956,73**, garantindo que o dado de saÃ­da seja o reflexo fiel e auditado do dado de entrada.

**Detalhamento das Camadas de Dados:**

| Etapa do Projeto | Arquivo / RepositÃ³rio | Papel TÃ©cnico no Ecossistema |
| :--- | :--- | :--- |
| **Dados Originais (Entrada)** | `data/transacoes_brutas.csv` | **Dataset de IngestÃ£o:** ContÃ©m 627 registros financeiros brutos que simulam o recebimento de arquivos de remessa bancÃ¡ria. |
| **Camada de Transporte** | **Aiven Kafka Topics** | **Evento em TrÃ¢nsito:** Onde o dado reside de forma imutÃ¡vel e criptografada (SSL) antes de ser consumido pelo Worker. |
| **PersistÃªncia Operacional** | **MongoDB (Collections)** | **Estado de LiquidaÃ§Ã£o:** Armazenamento NoSQL onde os documentos sÃ£o persistidos apÃ³s validaÃ§Ã£o de integridade. |
| **Dados Liquidados (SaÃ­da)** | `liquidacao_final_2026.csv` | **RelatÃ³rio de Fechamento:** Arquivo consolidado pelo script de auditoria, utilizado para prova de conciliaÃ§Ã£o e BI. |

**Rigor na ManipulaÃ§Ã£o dos Dados:**

* **Imutabilidade no Broker:** Uma vez que a transaÃ§Ã£o entra no cluster da **Aiven**, ela nÃ£o pode ser alterada. Isso garante que o relatÃ³rio de saÃ­da possa ser auditado contra o log original em caso de divergÃªncias.
* **SeguranÃ§a na Origem e Destino:** O trÃ¡fego entre o arquivo de entrada e a persistÃªncia final Ã© protegido por protocolos de autenticaÃ§Ã£o, evitando a injeÃ§Ã£o de transaÃ§Ãµes nÃ£o autorizadas no pipeline.
* **ConsistÃªncia de Valores:** O sistema utiliza tipagem rigorosa para garantir que valores monetÃ¡rios nÃ£o sofram arredondamentos indevidos durante a conversÃ£o de CSV para JSON (Kafka) e posteriormente para BSON (MongoDB).

> [!IMPORTANT]
> A correlaÃ§Ã£o exata entre o arquivo de entrada e o de saÃ­da Ã© a mÃ©trica definitiva de sucesso desta arquitetura. No **Bank Resilience 2026**, a paridade absoluta entre esses arquivos confirma uma taxa de **0% de perda de pacotes** em ambientes distribuÃ­dos.

---

## âš™ï¸ Detalhamento TÃ©cnico e ConfiguraÃ§Ãµes

A robustez da arquitetura **Bank Resilience 2026** reside na sua capacidade de operar de forma segura e portÃ¡til. Para que a comunicaÃ§Ã£o entre os componentes distribuÃ­dos (API no Railway, Broker na Aiven e Worker local) ocorra sem falhas, implementamos uma camada de configuraÃ§Ã£o baseada em **VariÃ¡veis de Ambiente (.env)** e protocolos de seguranÃ§a de nÃ­vel bancÃ¡rio.

Esta abordagem garante que credenciais sensÃ­veis e strings de conexÃ£o nunca fiquem expostas no cÃ³digo-fonte, facilitando a escalabilidade e o gerenciamento de diferentes ambientes (Desenvolvimento, HomologaÃ§Ã£o e ProduÃ§Ã£o).

### ğŸ” Protocolos de SeguranÃ§a e Conectividade

A integraÃ§Ã£o com o **Apache Kafka na Aiven** introduziu uma camada de seguranÃ§a crÃ­tica: o **SSL/TLS**. Diferente de brokers de mensageria simplificados, a comunicaÃ§Ã£o financeira exige autenticaÃ§Ã£o mÃºtua.

* **Criptografia em TrÃ¢nsito:** Todos os dados enviados da API ou consumidos pelo Worker trafegam sob o protocolo SSL, impedindo ataques de interceptaÃ§Ã£o (*Man-in-the-Middle*).
* **GestÃ£o de Certificados:** O sistema utiliza trÃªs arquivos fundamentais para estabelecer o handshake seguro:
    1.  `ca.pem`: Certificado da Autoridade Certificadora da Aiven.
    2.  `service.cert`: Certificado de acesso do serviÃ§o.
    3.  `service.key`: Chave privada para autenticaÃ§Ã£o do cliente.

### ğŸ“‹ VariÃ¡veis de Ambiente Essenciais

A tabela abaixo detalha os parÃ¢metros configurados para sustentar o ecossistema:

| VariÃ¡vel | Finalidade TÃ©cnica | Escopo |
| :--- | :--- | :--- |
| `KAFKA_BROKER_URL` | EndereÃ§o do cluster Aiven (ex: `kafka-target-bank.aivencloud.com:port`) | API / Worker |
| `KAFKA_TOPIC_NAME` | Nome do tÃ³pico transacional (ex: `transactions.resilience.2026`) | API / Worker |
| `MONGO_URI` | String de conexÃ£o para persistÃªncia no MongoDB Atlas ou Local | Worker |
| `CLOUDAMQP_URL` | Endpoint de conexÃ£o para o broker RabbitMQ (Fallback/ResiliÃªncia) | API / Worker |
| `SSL_CA_PATH` | Caminho local para o certificado `ca.pem` | Worker |
| `PORT` | Porta de execuÃ§Ã£o da API no ambiente Railway | API |

### ğŸ› ï¸ ConfiguraÃ§Ã£o de TÃ³picos e PartiÃ§Ãµes

Para suportar o volume de **R$ 91.484.956,73**, o Kafka foi configurado visando **Alta Disponibilidade**:

* **Replication Factor (Fator de ReplicaÃ§Ã£o):** Configurado para garantir que, caso um broker do cluster sofra indisponibilidade, os dados financeiros permaneÃ§am acessÃ­veis em outros nÃ³s.
* **Particionamento:** Estruturado para permitir o processamento paralelo em larga escala, permitindo que mÃºltiplos Workers consumam dados simultaneamente sem conflitos.
* **Retention Policy (RetenÃ§Ã£o):** Definida para manter o log de eventos por tempo suficiente para auditorias e reprocessamentos em caso de falha na camada de banco de dados.

> [!CAUTION]
> A seguranÃ§a desta configuraÃ§Ã£o Ã© o que permite ao sistema operar em conformidade com normas de proteÃ§Ã£o de dados. Sem o isolamento das variÃ¡veis e a criptografia SSL, a integridade das transaÃ§Ãµes estaria comprometida.

---

### ğŸ”‘ Gerenciamento de VariÃ¡veis de Ambiente (`.env`)

A seguranÃ§a de uma arquitetura financeira distribuÃ­da depende da separaÃ§Ã£o absoluta entre a lÃ³gica de cÃ³digo e as credenciais de infraestrutura. No **Bank Resilience 2026**, utilizamos arquivos de configuraÃ§Ã£o `.env` para gerenciar segredos e strings de conexÃ£o, garantindo que o sistema seja portÃ¡til e esteja em conformidade com as diretrizes de seguranÃ§a de dados e normas de conformidade bancÃ¡ria.

Esta abordagem impede a exposiÃ§Ã£o de segredos em sistemas de controle de versÃ£o (como o GitHub), mitigando riscos de acesso nÃ£o autorizado aos clusters de produÃ§Ã£o.

#### ğŸ› ï¸ EspecificaÃ§Ã£o TÃ©cnica das VariÃ¡veis

As variÃ¡veis abaixo sustentam o pipeline hÃ­brido, permitindo que o sistema alterne entre os protocolos de mensageria e mantenha a persistÃªncia Ã­ntegra.

| Categoria | VariÃ¡vel de Ambiente | DescriÃ§Ã£o e Impacto no Fluxo |
| :--- | :--- | :--- |
| **Infra Cloud** | `PORT` | Porta de execuÃ§Ã£o da API no **Railway**, permitindo a escuta de trÃ¡fego HTTP para ingestÃ£o. |
| **Broker Principal** | `KAFKA_BROKER` | Endpoint seguro (URI:Porta) do cluster **Aiven**. Essencial para o roteamento de mensagens via SSL. |
| **SeguranÃ§a SSL** | `KAFKA_CA_PATH` | Caminho absoluto para o certificado `ca.pem`, necessÃ¡rio para validar a identidade do cluster. |
| **Broker Suporte** | `RABBITMQ_URL` | String de conexÃ£o (AMQPS) para o broker CloudAMQP, utilizada para fluxos de resiliÃªncia. |
| **PersistÃªncia** | `MONGO_LOCAL_URI` | URI de conexÃ£o para o MongoDB onde ocorre a liquidaÃ§Ã£o final dos **R$ 91M**. |
| **IdentificaÃ§Ã£o** | `KAFKA_TOPIC` | Nome lÃ³gico do tÃ³pico transacional, garantindo o alinhamento entre Producer e Consumer. |

#### ğŸ“‚ Exemplo de ConfiguraÃ§Ã£o â€” Worker Local (`local-worker/.env`)

Este arquivo Ã© o coraÃ§Ã£o da operaÃ§Ã£o do Worker, contendo as pontas de conexÃ£o entre a nuvem e o banco de dados local.

```env
# Conectividade com Mensageria (HÃ­brida)
RABBITMQ_URL=amqps://usuario:senha@cluster-id.rmq.cloudamqp.com/vhost
KAFKA_BROKER=kafka-target-bank-resilience-2026.aivencloud.com:25373
KAFKA_TOPIC=transactions.financial.verified

# SeguranÃ§a e Criptografia Aiven (SSL/TLS)
KAFKA_CA_PATH=./certs/ca.pem
KAFKA_CERT_PATH=./certs/service.cert
KAFKA_KEY_PATH=./certs/service.key

# Camada de PersistÃªncia e LiquidaÃ§Ã£o
MONGO_LOCAL_URI=mongodb://localhost:27017/bank_db
```

## 7ï¸âƒ£ Etapas do Projeto (Lifecycle de Desenvolvimento)

O ciclo de vida do **Bank Resilience 2026** foi projetado seguindo as fases de maturidade de um sistema de missÃ£o crÃ­tica. A jornada evoluiu de um modelo de mensageria simples para um ecossistema de **Event Streaming** de alta performance, onde a infraestrutura da **Aiven** garante a persistÃªncia de logs de eventos e o **MongoDB** atua como o livro-razÃ£o (*ledger*) de liquidaÃ§Ã£o.

Cada etapa foi documentada para garantir que o fluxo de **R$ 91.484.956,73** fosse processado com integridade matemÃ¡tica e seguranÃ§a criptogrÃ¡fica.

### ğŸ—ºï¸ Fluxo de ImplementaÃ§Ã£o e Arquitetura

| Fase | DescriÃ§Ã£o TÃ©cnica e Operacional | Diferencial de Engenharia |
|:--- |:--- |:--- |
| ğŸŸ¢ **PersistÃªncia NoSQL** | Modelagem e configuraÃ§Ã£o do cluster **MongoDB**. Foco na criaÃ§Ã£o de coleÃ§Ãµes otimizadas para alta escrita e garantia de atomicidade na persistÃªncia final. | EstruturaÃ§Ã£o de schemas resilientes. |
| ğŸŸ¡ **Broker Multi-Cloud** | Provisionamento e configuraÃ§Ã£o do **Apache Kafka na Aiven**. DefiniÃ§Ã£o de tÃ³picos transacionais, fatores de replicaÃ§Ã£o e polÃ­ticas de retenÃ§Ã£o de mensagens. | Alta disponibilidade gerenciada. |
| ğŸ›¡ï¸ **Hardening de SeguranÃ§a** | ImplementaÃ§Ã£o de autenticaÃ§Ã£o mÃºtua via **SSL/TLS**. ConfiguraÃ§Ã£o de certificados `ca.pem`, `service.cert` e `service.key` para criptografia de ponta a ponta. | Conformidade com padrÃµes bancÃ¡rios. |
| ğŸ”µ **Deploy e IngestÃ£o** | PublicaÃ§Ã£o da API no **Railway** com integraÃ§Ã£o via CI/CD. ConfiguraÃ§Ã£o de variÃ¡veis de ambiente para orquestraÃ§Ã£o entre Cloud e Worker Local. | Portabilidade e escalabilidade. |
| ğŸŸ£ **Consumo e LiquidaÃ§Ã£o** | ExecuÃ§Ã£o de **Workers** especializados que processam o log do Kafka, garantindo o *manual commit* do offset apenas apÃ³s o sucesso da gravaÃ§Ã£o. | Garantia contra perda de dados. |
| ğŸ“Š **Auditoria e BI** | ExecuÃ§Ã£o dos scripts de conciliaÃ§Ã£o final, confrontando o dataset original com os documentos liquidados para emissÃ£o do relatÃ³rio de fechamento. | VerificaÃ§Ã£o de integridade contÃ¡bil. |

### ğŸ” EvoluÃ§Ã£o TÃ©cnica: De Mensageria a Log de Eventos

A transiÃ§Ã£o para o **Apache Kafka** permitiu que o projeto atingisse um novo patamar de resiliÃªncia:

1.  **Imutabilidade:** Diferente de filas tradicionais onde a mensagem Ã© deletada apÃ³s o consumo, o Kafka mantÃ©m o histÃ³rico das transaÃ§Ãµes, permitindo o reprocessamento em caso de incidentes.
2.  **SeguranÃ§a AvanÃ§ada:** A integraÃ§Ã£o com a **Aiven** forÃ§ou a implementaÃ§Ã£o de handshakes seguros via certificados, eliminando vulnerabilidades de rede aberta.
3.  **Observabilidade Nativa:** O uso de mÃ©tricas em tempo real (dashboard Aiven) permitiu monitorar a "saÃºde" do broker durante o processamento das 627 transaÃ§Ãµes.

> [!IMPORTANT]
> A organizaÃ§Ã£o destas etapas prova que a arquitetura nÃ£o Ã© apenas funcional, mas auditÃ¡vel. A paridade entre os dados de entrada e o relatÃ³rio de saÃ­da (0% de perda) Ã© o resultado direto da execuÃ§Ã£o rigorosa deste lifecycle de desenvolvimento.

## 8ï¸âƒ£ Endpoints da API

A API representa a **camada de entrada do sistema**, atuando como um Gateway de IngestÃ£o de Alta Disponibilidade. Sua responsabilidade primordial Ã© receber as transaÃ§Ãµes financeiras, realizar o handshake de seguranÃ§a e garantir que os dados sejam encaminhados de forma Ã­ntegra para o pipeline assÃ­ncrono, operando simultaneamente com **Apache Kafka (Aiven)** e **RabbitMQ (CloudAMQP)**.

Ela isola o cliente da complexidade interna da infraestrutura distribuÃ­da. Em cenÃ¡rios de alta carga ou picos de trÃ¡fego, a API preserva a experiÃªncia do usuÃ¡rio ao confirmar o recebimento do dado (*Acknowledgment*) e delegar o processamento pesado para os Brokers, garantindo que o montante de **R$ 91.484.956,73** seja capturado sem rejeiÃ§Ãµes de conexÃ£o.

### ğŸ›£ï¸ DefiniÃ§Ã£o das Rotas Transacionais

Abaixo, os endpoints estruturados para suportar o fluxo de dados do **Bank Resilience 2026**:

| MÃ©todo | Rota | DescriÃ§Ã£o TÃ©cnica e Arquitetural |
| :--- | :--- | :--- |
| **POST** | `/ingestao` | **Gateway de Entrada:** Recebe payloads JSON, valida a estrutura e despacha o evento para o **Kafka** e **RabbitMQ**. Ã‰ o ponto onde o dado bruto entra no ecossistema seguro. |
| **GET** | `/status` | **Health Check & Observabilidade:** Verifica em tempo real a saÃºde da instÃ¢ncia no **Railway** e a latÃªncia de conectividade com o Broker Aiven e o cluster MongoDB. |
| **POST** | `/webhook` | **InjeÃ§Ã£o de Eventos Externos:** Interface preparada para receber notificaÃ§Ãµes de terceiros, permitindo a integraÃ§Ã£o de eventos de parceiros diretamente no pipeline de auditoria. |

### ğŸ›¡ï¸ Engenharia de ResiliÃªncia na Camada HTTP

* **Desacoplamento de Processamento:** A API nÃ£o aguarda a persistÃªncia no banco de dados para responder ao cliente. Ela garante a entrega da mensagem ao Broker (Kafka/RabbitMQ), o que evita o bloqueio do Event Loop do Node.js e maximiza o throughput de entrada.
* **SeguranÃ§a de TrÃ¡fego:** Implementada sob HTTPS no **Railway**, a API gerencia as chaves de acesso e certificados **SSL/TLS** necessÃ¡rios para se comunicar com o cluster gerenciado na **Aiven**, assegurando que os dados financeiros nunca trafeguem de forma clara na rede.
* **Protocolo de Failover:** O endpoint de ingestÃ£o estÃ¡ configurado para tratar interrupÃ§Ãµes; caso o Broker principal apresente latÃªncia fora dos parÃ¢metros, o sistema estÃ¡ apto a gerenciar a fila de mensagens para garantir que nenhuma transaÃ§Ã£o seja descartada.

> [!NOTE]
> No contexto deste projeto, a API Ã© a "primeira linha de defesa". A paridade de 100% dos dados na auditoria final prova que esta camada de endpoints foi capaz de sustentar a ingestÃ£o das 627 transaÃ§Ãµes originais sem gerar erros de timeout ou perda de pacotes.

## 9ï¸âƒ£ Deploy & Infraestrutura (Arquitetura HÃ­brida)

A estratÃ©gia de infraestrutura do **Bank Resilience 2026** foi projetada para emular um ecossistema bancÃ¡rio real, onde os componentes sÃ£o distribuÃ­dos em camadas distintas para maximizar a seguranÃ§a e a resiliÃªncia. A arquitetura adota o conceito de **Desacoplamento GeogrÃ¡fico**, distribuindo a carga de trabalho entre diferentes provedores de nuvem e processamento local.

Essa separaÃ§Ã£o reforÃ§a princÃ­pios de **seguranÃ§a cibernÃ©tica e isolamento de falhas**, demonstrando como sistemas financeiros modernos gerenciam responsabilidades entre a borda (*Edge*), a mensageria de alto throughput e o core de persistÃªncia.

### ğŸ—ï¸ DistribuiÃ§Ã£o de Componentes e Responsabilidades

* **API Gateway (Hospedado no Railway):** Ambiente *Cloud-Native* responsÃ¡vel pela recepÃ§Ã£o das requisiÃ§Ãµes externas. Atua como o produtor de eventos (**Producer**), orquestrando a entrada de dados e garantindo que cada transaÃ§Ã£o seja assinada e enviada para o cluster Kafka com seguranÃ§a SSL.
* **Mensageria Gerenciada (Aiven & CloudAMQP):** UtilizaÃ§Ã£o de infraestrutura especializada para o transporte de dados. O **Apache Kafka na Aiven** atua como o *backbone* de eventos, provendo um log imutÃ¡vel de transaÃ§Ãµes com alta disponibilidade e replicaÃ§Ã£o de dados entre nÃ³s.
* **Internal Worker (ExecuÃ§Ã£o Local/On-Premise):** Simula o **Core BancÃ¡rio** interno. O Worker opera em uma rede protegida, consumindo as mensagens dos brokers e realizando a liquidaÃ§Ã£o final no MongoDB. Esta separaÃ§Ã£o garante que, mesmo que a API sofra um ataque externo, o processador de pagamentos e o banco de dados permaneÃ§am isolados.
* **GovernanÃ§a via VariÃ¡veis de Ambiente (`.env`):** Seguindo o manifesto *Twelve-Factor App*, todas as configuraÃ§Ãµes sensÃ­veis (certificados SSL, URIs e chaves de acesso) sÃ£o injetadas dinamicamente, eliminando o risco de exposiÃ§Ã£o de credenciais no cÃ³digo-fonte.

### ğŸ›¡ï¸ Engenharia de ResiliÃªncia e PersistÃªncia



* **Mensageria DurÃ¡vel e Persistente:** Tanto no RabbitMQ (`durable: true`) quanto no Kafka (configuraÃ§Ãµes de `retention` e `replication factor`), o sistema Ã© configurado para sobreviver a reinicializaÃ§Ãµes dos brokers. No Kafka, o dado Ã© gravado em disco de forma sequencial, garantindo que o montante de **R$ 91.484.956,73** esteja seguro mesmo se o Worker ficar offline.
* **Protocolo de Manual Ack/Commit:** A infraestrutura foi configurada para nÃ£o aceitar confirmaÃ§Ãµes automÃ¡ticas. O "visto" de processado sÃ³ Ã© enviado ao broker apÃ³s a confirmaÃ§Ã£o de escrita (*Write Concern*) no MongoDB, eliminando perdas de dados em trÃ¢nsito.
* **Conectividade Criptografada (SSL/TLS):** A infraestrutura de rede utiliza tÃºneis criptografados para a comunicaÃ§Ã£o entre o Railway e a Aiven, garantindo a integridade e a confidencialidade do trÃ¡fego financeiro em redes pÃºblicas.

> [!IMPORTANT]
> A escolha de uma arquitetura hÃ­brida prova a capacidade do sistema em operar sob o modelo de **Lock-in Avoidance** (evitar dependÃªncia de um Ãºnico fornecedor), permitindo que o processamento seja escalado ou movido entre nuvens sem interrupÃ§Ã£o do serviÃ§o bancÃ¡rio.

## ğŸ”Ÿ Stack TecnolÃ³gica (Enterprise Grade)

A escolha da stack tecnolÃ³gica do **Bank Resilience 2026** prioriza **desempenho de baixa latÃªncia, escalabilidade horizontal e confiabilidade transacional**. As tecnologias selecionadas sÃ£o padrÃµes de indÃºstria em sistemas financeiros modernos, permitindo a orquestraÃ§Ã£o de dados entre ambientes *on-premise* e mÃºltiplos provedores de nuvem (*Multi-Cloud*).

Cada componente cumpre um papel estratÃ©gico, garantindo que a ingestÃ£o, o transporte e a liquidaÃ§Ã£o dos dados ocorram sob protocolos de seguranÃ§a rigorosos e alta disponibilidade.

### ğŸ’» Core de Desenvolvimento e PersistÃªncia

* **Backend: Node.js & Express**
    Plataforma orientada a eventos e I/O nÃ£o bloqueante, ideal para construir APIs de alta concorrÃªncia. No projeto, o Node.js gerencia o ciclo de vida das mensagens e o handshake SSL com o Kafka, mantendo o throughput estÃ¡vel durante a ingestÃ£o massiva.
* **Banco de Dados: MongoDB (Mongoose)**
    Banco NoSQL orientado a documentos, utilizado para a persistÃªncia final das transaÃ§Ãµes. Sua flexibilidade de schema permite evoluir a estrutura de dados financeira sem downtime, enquanto seu motor de agregaÃ§Ã£o sustenta o processo de **Auditoria Financeira**.

### ğŸ“¨ Camada de Mensageria e Event Streaming



* **Event Streaming: Apache Kafka (Aiven)**
    Atua como o *backbone* de dados do projeto. Diferente de brokers tradicionais, o Kafka armazena o log de eventos de forma imutÃ¡vel, permitindo durabilidade extrema e a capacidade de reprocessar transaÃ§Ãµes (Replay) em cenÃ¡rios de recuperaÃ§Ã£o de desastres.
* **Mensageria: RabbitMQ (amqplib)**
    Utilizado como broker de suporte para filas durÃ¡veis e entrega garantida. Sua implementaÃ§Ã£o garante o desacoplamento entre a API de ingestÃ£o e os workers de processamento, provendo alta granularidade no controle de mensagens.

### â˜ï¸ Infraestrutura e Cloud

* **Hospedagem de API: Railway**
    Plataforma de PaaS (*Platform as a Service*) que sustenta a API de ingestÃ£o, provendo escalabilidade automÃ¡tica e gerenciamento seguro de segredos de infraestrutura.
* **Broker Gerenciado: Aiven**
    Provedor especializado em infraestrutura de dados em nuvem, responsÃ¡vel por hospedar o cluster Kafka com monitoramento em tempo real, backups automÃ¡ticos e seguranÃ§a **SSL/TLS** nativa.
* **Cloud Broker: CloudAMQP**
    InstÃ¢ncia gerenciada de RabbitMQ, garantindo que o serviÃ§o de mensageria opere em um ambiente isolado e de alta disponibilidade.

### ğŸ› ï¸ Ecossistema de Apoio e GovernanÃ§a

* **SeguranÃ§a:** Protocolos **SSL/TLS** para criptografia em trÃ¢nsito e **Dotenv** para isolamento de credenciais sensÃ­veis.
* **Qualidade e Testes:** **Postman** para validaÃ§Ã£o rigorosa dos contratos da API e **Git** para versionamento distribuÃ­do.
* **Observabilidade:** Dashboards de mÃ©tricas da Aiven para monitoramento de throughput e saÃºde do cluster em janelas de 1h e 24h.

> [!IMPORTANT]
> A integraÃ§Ã£o desta stack tecnolÃ³gica nÃ£o Ã© apenas uma lista de ferramentas, mas uma arquitetura de **ResiliÃªncia de Dados**. O uso combinado de Kafka e MongoDB assegura que cada centavo dos **R$ 91.484.956,73** seja rastreÃ¡vel, do log de eventos ao registro final no banco de dados.

## 1ï¸âƒ£1ï¸âƒ£ Programas e ServiÃ§os Utilizados (Ecossistema de Infraestrutura)

A construÃ§Ã£o do **Bank Resilience 2026** envolveu a orquestraÃ§Ã£o de ferramentas profissionais de alta performance, amplamente adotadas em arquiteturas de dados e backend em nuvem. A seleÃ§Ã£o abaixo garante que o sistema suporte o processamento de **R$ 91.484.956,73** com seguranÃ§a criptogrÃ¡fica e alta disponibilidade.

### ğŸ› ï¸ Matriz de Ferramentas e Finalidades TÃ©cnicas

| Categoria | Ferramenta | Papel EstratÃ©gico no Projeto |
| :--- | :--- | :--- |
| **Runtime** | **Node.js (LTS)** | Motor de execuÃ§Ã£o orientado a eventos, responsÃ¡vel pelo processamento assÃ­ncrono e gerenciamento de streams de dados. |
| **Framework Web** | **Express** | Camada de middleware para criaÃ§Ã£o do Gateway de IngestÃ£o e rotas de monitoramento de saÃºde da API. |
| **Event Streaming** | **Apache Kafka (Aiven)** | Broker principal de alta performance. Gerencia o log de eventos imutÃ¡vel com persistÃªncia garantida em disco. |
| **Mensageria** | **RabbitMQ (CloudAMQP)** | Broker de suporte para filas durÃ¡veis, garantindo o desacoplamento e a entrega confiÃ¡vel das mensagens. |
| **Banco de Dados** | **MongoDB (Atlas / Local)** | Camada de persistÃªncia NoSQL (Document Store) onde ocorre a liquidaÃ§Ã£o e o armazenamento final auditado. |
| **ODM / Modelagem** | **Mongoose** | Framework de modelagem de objetos para garantir a tipagem rigorosa e a validaÃ§Ã£o dos dados financeiros antes da escrita. |
| **Cloud / Deploy** | **Railway** | Plataforma de nuvem (PaaS) que sustenta a API, provendo escalabilidade e integraÃ§Ã£o direta com o GitHub. |
| **SeguranÃ§a** | **OpenSSL / Certificados** | GeraÃ§Ã£o e gestÃ£o de certificados `.pem` para estabelecer conexÃµes seguras (**SSL/TLS**) entre os serviÃ§os. |
| **Testes de Stress** | **Postman** | Ferramenta de validaÃ§Ã£o de endpoints e simulaÃ§Ã£o de cargas de dados para testar a resiliÃªncia da API. |
| **GovernanÃ§a** | **Git / GitHub** | Versionamento distribuÃ­do e controle de histÃ³rico de alteraÃ§Ãµes, garantindo a integridade do cÃ³digo-fonte. |
| **ConfiguraÃ§Ã£o** | **Dotenv** | GestÃ£o de segredos e variÃ¡veis de ambiente, isolando as credenciais de infraestrutura do cÃ³digo-fonte. |

### ğŸ” Justificativa da Escolha de Infraestrutura

O uso conjunto de **Aiven (Kafka)** e **Railway (API)** permite que o sistema opere em uma arquitetura de **Nuvem HÃ­brida**. Enquanto o Railway oferece agilidade para o frontend de ingestÃ£o, a Aiven provÃª a robustez necessÃ¡ria para o trÃ¡fego de mensagens financeiras, oferecendo dashboards de monitoramento que comprovam a estabilidade do sistema sob carga.

A inclusÃ£o do **Upstash** no pipeline serve como uma camada adicional de auditoria e agendamento assÃ­ncrono, permitindo que o sistema execute tarefas de limpeza ou verificaÃ§Ã£o de logs sem impactar a performance do core de processamento.

> [!IMPORTANT]
> A integraÃ§Ã£o destas ferramentas foi configurada para suportar falhas parciais: se um serviÃ§o de nuvem apresentar instabilidade, os mecanismos de *retry* e as filas durÃ¡veis (RabbitMQ/Kafka) garantem que as transaÃ§Ãµes fiquem retidas atÃ© a completa recuperaÃ§Ã£o do sistema, mantendo a integridade dos dados financeiros.

---

## ğŸ–¼ï¸ 1ï¸âƒ£2ï¸âƒ£ EvidÃªncias Operacionais do Ambiente de ExecuÃ§Ã£o

O registro visual do ambiente de execuÃ§Ã£o complementa a documentaÃ§Ã£o arquitetural do projeto, fornecendo evidÃªncias da implementaÃ§Ã£o prÃ¡tica da soluÃ§Ã£o, da integraÃ§Ã£o entre os componentes do ecossistema e da validaÃ§Ã£o operacional das camadas que compÃµem o sistema.

Abaixo estÃ£o as evidÃªncias tÃ©cnicas de cada camada do pipeline, extraÃ­das diretamente dos painÃ©is de monitoramento e ferramentas de desenvolvimento.

---

### ğŸ“ˆ Monitoramento de Infraestrutura (Aiven Console)

As mÃ©tricas de desempenho coletadas via **Aiven** fornecem a prova empÃ­rica da estabilidade do **Broker Kafka**. O monitoramento contÃ­nuo garante que o throughput de **R$ 91.484.956,73** nÃ£o sofra gargalos de processamento.

#### ğŸ”¹ MÃ©tricas de Performance (CPU & MemÃ³ria)
VisualizaÃ§Ã£o detalhada do consumo de recursos do cluster em janelas de **1 hora** e **24 horas**, comprovando:
* **ResiliÃªncia do hardware:** Estabilidade tÃ©rmica e de processamento.
* **ManutenÃ§Ã£o da saÃºde do sistema:** OperaÃ§Ã£o constante sob carga transacional.
* **Estabilidade do ambiente:** AusÃªncia de saturaÃ§Ã£o em picos de processamento.

#### ğŸ”¹ Taxas de TransferÃªncia (Network Throughput)
Registros de entrada e saÃ­da de dados que validam a eficiÃªncia do pipeline entre:
* **Railway:** ResponsÃ¡vel pela IngestÃ£o de Dados.
* **Worker Local:** ResponsÃ¡vel pelo Processamento e LiquidaÃ§Ã£o.

---

### ğŸ—ï¸ ConfiguraÃ§Ã£o de TÃ³picos e ResiliÃªncia

A estruturaÃ§Ã£o lÃ³gica dentro do **Apache Kafka** garante imutabilidade e alta disponibilidade dos dados financeiros atravÃ©s de uma arquitetura de log de eventos distribuÃ­do.

#### ğŸ”¹ TÃ³picos e PartiÃ§Ãµes
EvidÃªncia da criaÃ§Ã£o do tÃ³pico transacional e sua segmentaÃ§Ã£o em partiÃ§Ãµes, permitindo:
* **Paralelismo no consumo:** Processamento multithreaded.
* **Escalabilidade horizontal:** Capacidade de expansÃ£o do ecossistema.
* **DistribuiÃ§Ã£o eficiente de carga:** EquilÃ­brio de trÃ¡fego entre os nÃ³s do cluster.

#### ğŸ”¹ Fator de ReplicaÃ§Ã£o
DocumentaÃ§Ã£o visual que comprova a replicaÃ§Ã£o dos dados entre os nÃ³s do cluster na Aiven, assegurando que:
* A falha de um broker individual nÃ£o resulte em perda de mensagens (Durabilidade).

---

### ğŸ“‚ Logs de OperaÃ§Ã£o e SeguranÃ§a SSL/TLS

A validaÃ§Ã£o final ocorre na camada de aplicaÃ§Ã£o, onde o handshake seguro e a persistÃªncia atÃ´mica sÃ£o confirmados por registros de auditoria.

#### ğŸ”¹ Handshake SSL/TLS
Logs do terminal demonstrando autenticaÃ§Ã£o mÃºtua bem-sucedida via certificados `.pem`, estabelecendo:
* **TÃºnel criptografado:** ProteÃ§Ã£o de dados sensÃ­veis em trÃ¢nsito.
* **ComunicaÃ§Ã£o segura:** PrevenÃ§Ã£o contra ataques de interceptaÃ§Ã£o (*MitM*).
* **Conformidade:** Alinhamento com padrÃµes de seguranÃ§a do setor bancÃ¡rio.

#### ğŸ”¹ Consumo e LiquidaÃ§Ã£o
Registros em tempo real do Worker processando **627 transaÃ§Ãµes**, culminando no relatÃ³rio de auditoria final que confirma:
* **Paridade absoluta dos valores:** DiferenÃ§a zero entre origem e destino.
* **PersistÃªncia correta no MongoDB:** GravaÃ§Ã£o definitiva apÃ³s o processamento.
* **Integridade transacional:** Fluxo fim a fim sem corrupÃ§Ã£o de dados.

---
> [!IMPORTANT]

> ### âœ… ConclusÃ£o de Auditoria
> A convergÃªncia entre as mÃ©tricas de infraestrutura e os logs de execuÃ§Ã£o atesta o sucesso da arquitetura de **Zero Data Loss**. O sistema provou-se capaz de sustentar o fluxo financeiro planejado com integridade total de dados, garantindo:
> * **Confiabilidade operacional** e resiliÃªncia a falhas crÃ­ticas.
> * **SeguranÃ§a na transmissÃ£o** via protocolos criptogrÃ¡ficos avanÃ§ados.
> * **ConsistÃªncia na persistÃªncia** e rastreabilidade total do montante processado.
---

## ğŸ–¼ï¸ EvidÃªncias Operacionais

O registro visual abaixo detalha o monitoramento, a infraestrutura e os testes de resiliÃªncia realizados no sistema.

### â˜ï¸ Infraestrutura e IDE
| VS Code Projeto | Railway API | Deployments | MÃ©tricas API |
| :---: | :---: | :---: | :---: |
| <img src="img/01-vscode_projeto.png" width="200"/> | <img src="img/01-railway_api_bancario_resilience.png" width="200"/> | <img src="img/02-railway_api_bancario_resilience-deployments.png" width="200"/> | <img src="img/03-railway_api_bancario_resilience-metrics.png" width="200"/> |

---

### ğŸš€ Apache Kafka (Aiven)
| CPU 1h | MEM 1h | CPU 1d | MEM 1d |
| :---: | :---: | :---: | :---: |
| <img src="img/01-kafka-metrics_1hour.png" width="200"/> | <img src="img/02-kafka-metrics_1hour.png" width="200"/> | <img src="img/03-kafka-metrics_1day.png" width="200"/> | <img src="img/04-kafka-metrics_1day.png" width="200"/> |

| Logs | Topics | Info | Broker |
| :---: | :---: | :---: | :---: |
| <img src="img/02-kafka-logs.png" width="200"/> | <img src="img/03-kafka-topics.png" width="200"/> | <img src="img/04-kafka-topics-info.png" width="200"/> | <img src="img/05-kafka-topics-info_broker.png" width="200"/> |

| Partitions | TrÃ¡fego | Consumer Groups | - |
| :---: | :---: | :---: | :---: |
| <img src="img/06-kafka-topics-info_partitions.png" width="200"/> | <img src="img/07-kafka-topics-dados_trafego.png" width="200"/> | <img src="img/07-kafka-topics-info_consumer_groups.png" width="200"/> | |

---

### ğŸ“¨ RabbitMQ (CloudAMQP)
| Channels | Connections | Exchanges | Monitor MP |
| :---: | :---: | :---: | :---: |
| <img src="img/01-cloudamqp-bank-resilience-channels.png" width="200"/> | <img src="img/02-cloudamqp-bank-resilience-connections.png" width="200"/> | <img src="img/03-cloudamqp-bank-resilience-exchanges.png" width="200"/> | <img src="img/04-cloudamqp-bank-resilience-mp.png" width="200"/> |

| Overview | Queues | - | - |
| :---: | :---: | :---: | :---: |
| <img src="img/05-cloudamqp-bank-resilience-overview.png" width="200"/> | <img src="img/06-cloudamqp-bank-resilience-queues_and_streams.png" width="200"/> | | |

---

### ğŸ—„ï¸ MongoDB (Compass)
| Documents | Aggregations | Schema | Indexes |
| :---: | :---: | :---: | :---: |
| <img src="img/01-mongodb-campass-documents.png" width="200"/> | <img src="img/02-mongodb-campass-aggregations.png" width="200"/> | <img src="img/02-mongodb-campass-schema.png" width="200"/> | <img src="img/04-mongodb-campass-indexes.png" width="200"/> |

---

### ğŸ”„ Testes & Reprocessamento (Postman)
| Postman Send | Postman CloudAMQP | Postman Railway | Log Cloud |
| :---: | :---: | :---: | :---: |
| <img src="img/01-postman_send.png" width="200"/> | <img src="img/02-postman_send-cloudamqp.png" width="200"/> | <img src="img/03-postman_send_railway.png" width="200"/> | <img src="img/01-cloudamqp- postman_send.png" width="200"/> |

| Reprocessar 01 | Reprocessar 02 | - | - |
| :---: | :---: | :---: | :---: |
| <img src="img/01-enviando_reprocessamento.png" width="200"/> | <img src="img/02-enviado_reprocessando.png" width="200"/> | | |

---

> [!CHECK]
> **ConclusÃ£o de Auditoria Visual:** A integraÃ§Ã£o entre as ferramentas de monitoramento (Aiven/Railway/CloudAMQP) e os logs de execuÃ§Ã£o comprovam que o sistema atingiu **100% de integridade transacional**, processando o montante de **R$ 91.484.956,73** sem divergÃªncias.

## ğŸ‘¤ 1ï¸âƒ£3ï¸âƒ£ Autor

**Roney Cesar** Analista em Desenvolvimento de Sistemas, com foco na integraÃ§Ã£o entre desenvolvimento de software e engenharia de dados.

Este projeto foi desenvolvido como estudo educacional e simulaÃ§Ã£o de um cenÃ¡rio financeiro real, com Ãªnfase em:

- **Arquiteturas resilientes para sistemas bancÃ¡rios:** ImplementaÃ§Ã£o de padrÃµes que garantem a continuidade dos serviÃ§os e a integridade transacional, minimizando pontos Ãºnicos de falha.  
- **Processamento assÃ­ncrono de transaÃ§Ãµes:** UtilizaÃ§Ã£o de mensageria para o desacoplamento de microserviÃ§os, permitindo que o sistema processe altos volumes de transaÃ§Ãµes sem comprometer a latÃªncia da API.  
- **Engenharia de dados aplicada a APIs:** EstruturaÃ§Ã£o e modelagem de fluxos de dados ponta a ponta, garantindo que a informaÃ§Ã£o trafegue com seguranÃ§a entre produtores e consumidores.  
- **Boas prÃ¡ticas de mensageria e tolerÃ¢ncia a falhas:** ConfiguraÃ§Ã£o avanÃ§ada de Brokers (Kafka/RabbitMQ) com foco em reprocessamento (retry), monitoramento de mÃ©tricas e garantias de entrega.  
- **IntegraÃ§Ã£o entre backend, banco de dados e serviÃ§os em nuvem:** OrquestraÃ§Ã£o de infraestrutura distribuÃ­da utilizando PaaS (Railway) e bancos NoSQL (MongoDB) para uma soluÃ§Ã£o escalÃ¡vel e auditÃ¡vel.

## ğŸ“š 1ï¸âƒ£4ï¸âƒ£ ReferÃªncias e Fontes de Estudo

O desenvolvimento deste projeto foi baseado em pesquisa tÃ©cnica e aprendizado contÃ­nuo por meio de:

### ğŸ› ï¸ Tecnologias e ServiÃ§os Utilizados
- **Hospedagem e Cloud (PaaS):** [Railway](https://railway.app/) - Plataforma utilizada para deploy e monitoramento da API.
- **Mensageria Apache Kafka:** [Aiven](https://aiven.io/) - ServiÃ§o gerenciado para o cluster Kafka e mÃ©tricas de performance.
- **Mensageria RabbitMQ:** [CloudAMQP](https://www.cloudamqp.com/) - Broker utilizado para o processamento assÃ­ncrono e filas.
- **Banco de Dados NoSQL:** [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) & [Compass](https://www.mongodb.com/products/compass) - PersistÃªncia de dados e auditoria.
- **Runtime e Framework:** [Java / Spring Boot](https://spring.io/projects/spring-boot) (ou Node.js conforme sua implementaÃ§Ã£o) - Core do desenvolvimento backend.
- **Testes de API:** [Postman](https://www.postman.com/) - DocumentaÃ§Ã£o e validaÃ§Ã£o de endpoints e fluxos de reprocessamento.

### ğŸ“– Fontes de Aprendizado
- **DocumentaÃ§Ãµes Oficiais:** Consultas constantes aos manuais tÃ©cnicos do Node.js, MongoDB, RabbitMQ e documentaÃ§Ã£o do cluster Aiven.
- **ConteÃºdos Educacionais:** Tutoriais tÃ©cnicos e estudos de caso de arquitetura de software disponÃ­veis no YouTube e plataformas de desenvolvimento.
- **InteligÃªncia Artificial:** UtilizaÃ§Ã£o de ferramentas de IA para apoio conceitual, validaÃ§Ã£o de arquiteturas resilientes e revisÃ£o de abordagens tÃ©cnicas.
- **Engenharia de Software:** AplicaÃ§Ã£o de boas prÃ¡ticas em sistemas distribuÃ­dos, padrÃµes de resiliÃªncia e ambientes financeiros de missÃ£o crÃ­tica.
